{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from urllib.request import urlopen\n",
    "import scipy.optimize\n",
    "import random\n",
    "from math import exp\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseData(fname):\n",
    "  for l in urlopen(fname):\n",
    "    yield eval(l)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "print(\"Reading data...\")\n",
    "data = list(parseData(\"http://jmcauley.ucsd.edu/cse190/data/beer/beer_50000.json\"))\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature(datum):\n",
    "  feat = [1, datum['review/taste'], datum['review/appearance'], datum['review/aroma'], datum['review/palate'], datum['review/overall']]\n",
    "  return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [feature(d) for d in data]\n",
    "y = [d['beer/ABV'] >= 6.5 for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner(x,y):\n",
    "  return sum([x[i]*y[i] for i in range(len(x))])\n",
    "\n",
    "def sigmoid(x):\n",
    "  return 1.0 / (1 + exp(-x))\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Logistic regression by gradient ascent  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NEGATIVE Log-likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(theta, X, y, lam):\n",
    "  loglikelihood = 0\n",
    "  for i in range(len(X)): \n",
    "    logit = inner(X[i], theta)\n",
    "    loglikelihood -= log(1 + exp(-logit))\n",
    "    if not y[i]:\n",
    "      loglikelihood -= logit\n",
    "  for k in range(len(theta)):\n",
    "    loglikelihood -= lam * theta[k]*theta[k]\n",
    "  # for debugging\n",
    "  # print(\"ll =\" + str(loglikelihood))\n",
    "  return -loglikelihood "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NEGATIVE Derivative of log-likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fprime(theta, X, y, lam):\n",
    "  dl = [0]*len(theta)\n",
    "  for i in range(len(X)):\n",
    "    logit = inner(X[i], theta)\n",
    "    for k in range(len(theta)):\n",
    "      dl[k] += X[i][k] * (1 - sigmoid(logit))\n",
    "      if not y[i]:\n",
    "        dl[k] -= X[i][k]\n",
    "  for k in range(len(theta)):\n",
    "    dl[k] -= lam*2*theta[k]\n",
    "  return np.array([-x for x in dl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_data = random.sample(data, int(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [feature(d) for d in rand_data]\n",
    "y = [d['beer/ABV'] >= 6.5 for d in rand_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = int(len(rand_data) * (1/3))\n",
    "\n",
    "X_train = X[:n_train]\n",
    "y_train = y[:n_train]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test = int((len(rand_data) - n_train) * (1/2))\n",
    "\n",
    "X_test = X[n_train:(n_train+n_test)]\n",
    "y_test = y[n_train:(n_train+n_test)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = X[n_train+n_test:]\n",
    "y_val = y[n_train+n_test:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(lam):\n",
    "  theta,_,_ = scipy.optimize.fmin_l_bfgs_b(f, [0]*len(X[0]), fprime, pgtol = 10, args = (X_train, y_train, lam))\n",
    "  return theta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance(theta, X, y):\n",
    "    scores = [inner(theta,x) for x in X]\n",
    "    predictions = [s > 0 for s in scores]\n",
    "    correct = [(a==b) for (a,b) in zip(predictions,y)]\n",
    "    acc = sum(correct) * 1.0 / len(correct)\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam = 1.0\n",
    "\n",
    "theta = train(lam)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_acc = performance(theta, X_val, y_val)\n",
    "test_acc = performance(theta, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda = 1.0:\tvalidation accuracy = 0.7169856602867942\n",
      "lambda = 1.0:\ttest accuracy = 0.7217255654886903\n"
     ]
    }
   ],
   "source": [
    "print(\"lambda = \" + str(lam) + \":\\tvalidation accuracy = \" + str(val_acc))\n",
    "print(\"lambda = \" + str(lam) + \":\\ttest accuracy = \" + str(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance(theta, X, y):\n",
    "    scores = [inner(theta,x) for x in X]\n",
    "    predictions = [s > 0 for s in scores]\n",
    "    \n",
    "    true_pos = [(1 if(a==b and a==1) else 0) for (a,b) in zip(predictions, y)]\n",
    "    true_pos = sum(true_pos)\n",
    "    \n",
    "    true_neg = [(1 if(a==b and a==0) else 0) for (a,b) in zip(predictions, y)]\n",
    "    true_neg = sum(true_neg)\n",
    "    \n",
    "    false_pos = [(1 if(a!=b and a==1) else 0) for (a,b) in zip(predictions, y)]\n",
    "    false_pos = sum(false_pos)\n",
    "    \n",
    "    false_neg = [(1 if(a!=b and a==0) else 0) for (a,b) in zip(predictions, y)]\n",
    "    false_neg = sum(false_neg)\n",
    "    \n",
    "    true_pos_rate = float(true_pos)/float((true_pos+false_neg))\n",
    "    true_neg_rate = float(true_neg)/float((true_neg+false_pos))\n",
    "    BER = 1 - 0.5*(true_pos_rate + true_neg_rate)\n",
    "    \n",
    "    return true_pos, true_neg, false_pos, false_neg, BER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda = 1.0:\t# of true postives = 9113\n",
      "lambda = 1.0:\t# of true negative = 2916\n",
      "lambda = 1.0:\t# of false postives = 3319\n",
      "lambda = 1.0:\t# of false negatives = 1319\n",
      "lambda = 1.0:\tBalanced Error Rate = 0.32937772279237043\n"
     ]
    }
   ],
   "source": [
    "true_pos, true_neg, false_pos, false_neg, BER = performance(theta, X_test, y_test)\n",
    "print(\"lambda = \" + str(lam) + \":\\t# of true postives = \" + str(true_pos))\n",
    "print(\"lambda = \" + str(lam) + \":\\t# of true negative = \" + str(true_neg))\n",
    "print(\"lambda = \" + str(lam) + \":\\t# of false postives = \" + str(false_pos))\n",
    "print(\"lambda = \" + str(lam) + \":\\t# of false negatives = \" + str(false_neg))\n",
    "print(\"lambda = \" + str(lam) + \":\\tBalanced Error Rate = \" + str(BER))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assigning more importance to FP means that the predictor will predict FP at higher accuracy therefore reduce the number of FP than before.\n",
    "To achieve this, I need to lower the possibility of predicting positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid1(x):\n",
    "  return 1.0 / (1 + exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(theta, X, y, lam):\n",
    "  loglikelihood = 0\n",
    "  for i in range(len(X)):\n",
    "    logit = inner(X[i], theta)\n",
    "    loglikelihood -= log(1 + exp(-logit))\n",
    "    if not y[i]:\n",
    "      loglikelihood -= logit\n",
    "  for k in range(len(theta)):\n",
    "    loglikelihood -= lam * theta[k]*theta[k]\n",
    "  # for debugging\n",
    "  # print(\"ll =\" + str(loglikelihood))\n",
    "  return -loglikelihood\n",
    "\n",
    "# NEGATIVE Derivative of log-likelihood\n",
    "def fprime1(theta, X, y, lam):\n",
    "  dl = [0]*len(theta)\n",
    "  for i in range(len(X)):\n",
    "    logit = inner(X[i], theta)\n",
    "    for k in range(len(theta)):\n",
    "      dl[k] += X[i][k] * (1 - sigmoid1(logit))\n",
    "      if not y[i]:\n",
    "        dl[k] -= X[i][k]\n",
    "  for k in range(len(theta)):\n",
    "    dl[k] -= lam*2*theta[k]\n",
    "  return np.array([-x for x in dl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train1(lam):\n",
    "  theta,_,_ = scipy.optimize.fmin_l_bfgs_b(f1, [0]*len(X[0]), fprime1, pgtol = 10, args = (X_train, y_train, lam))\n",
    "  return theta\n",
    "lam = 1\n",
    "theta = train1(lam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3319"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_pos, true_neg, false_pos, false_neg, BER = performance(theta, X_test, y_test)\n",
    "false_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda = 0:\tvalidation balanced error rate = 0.3321638727733528\n",
      "lambda = 0.01:\tvalidation balanced error rate = 0.33202129345905806\n",
      "lambda = 0.1:\tvalidation balanced error rate = 0.3320564381370883\n",
      "lambda = 1:\tvalidation balanced error rate = 0.3325546340691665\n",
      "lambda = 100:\tvalidation balanced error rate = 0.4209951010541717\n",
      "\n",
      "best value of lambda = 100:\ttrain balanced error rate = 0.32989111313036745\n",
      "best value of lambda = 100:\tvalidation balanced error rate = 0.33202129345905806\n",
      "best value of lambda = 100:\ttest balanced error rate = 0.3292136172827055\n"
     ]
    }
   ],
   "source": [
    "ber = {}\n",
    "for lam in [0, 0.01, 0.1, 1, 100]:\n",
    "    theta = train(lam)\n",
    "    val_ber = performance(theta, X_val, y_val)[4]\n",
    "    ber[val_ber] = lam\n",
    "    print(\"lambda = \" + str(lam) + \":\\tvalidation balanced error rate = \" + str(val_ber))\n",
    "\n",
    "best_ber = min(ber.keys())\n",
    "best_lam = ber[best_ber]\n",
    "theta = train(best_lam)\n",
    "train_ber = performance(theta, X_train, y_train)[4]\n",
    "val_ber = performance(theta, X_val, y_val)[4]\n",
    "test_ber = performance(theta, X_test, y_test)[4]\n",
    "print()\n",
    "print(\"best value of lambda = \" + str(lam) + \":\\ttrain balanced error rate = \" + str(train_ber))\n",
    "print(\"best value of lambda = \" + str(lam) + \":\\tvalidation balanced error rate = \" + str(val_ber))\n",
    "print(\"best value of lambda = \" + str(lam) + \":\\ttest balanced error rate = \" + str(test_ber))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting networkx\n",
      "Collecting decorator>=4.3.0 (from networkx)\n",
      "  Using cached https://files.pythonhosted.org/packages/bc/bb/a24838832ba35baf52f32ab1a49b906b5f82fb7c76b2f6a7e35e140bac30/decorator-4.3.0-py2.py3-none-any.whl\n",
      "Installing collected packages: decorator, networkx\n",
      "Successfully installed decorator-4.3.0 networkx-2.2\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "edges = set()\n",
    "nodes = set()\n",
    "for edge in urllib.request.urlopen(\"http://jmcauley.ucsd.edu/cse258/data/facebook/egonet.txt\"):\n",
    "  x,y = edge.split()\n",
    "  x,y = int(x),int(y)\n",
    "  edges.add((x,y))\n",
    "  edges.add((y,x))\n",
    "  nodes.add(x)\n",
    "  nodes.add(y)\n",
    "    \n",
    "G = nx.Graph()\n",
    "for e in edges:\n",
    "  G.add_edge(e[0],e[1])\n",
    "nx.draw(G)\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 connected components are in the graph.\n"
     ]
    }
   ],
   "source": [
    "component = len(list(nx.connected_component_subgraphs(G)))\n",
    "print(str(component) + \" connected components are in the graph.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[774, 708, 729, 863, 819, 753, 856, 869, 713, 828, 719, 697, 823, 810, 889, 880, 769, 890, 800, 747, 745, 805, 886, 840, 878, 876, 830, 703, 882, 861, 811, 864, 804, 772, 888, 825, 803, 893, 884, 798]\n"
     ]
    }
   ],
   "source": [
    "largest = max(nx.connected_component_subgraphs(G), key=len)\n",
    "type(largest)\n",
    "print(largest.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 nodes are in the largest component.\n"
     ]
    }
   ],
   "source": [
    "print(str(nx.number_of_nodes(largest)) + \" nodes are in the largest component.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "highest = sorted(largest.nodes())[21:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowest = sorted(largest.nodes())[:21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nedges(graph, cluster1, cluster2):\n",
    "    boundary_edge_iter = nx.edge_boundary(graph,cluster1,cluster2)\n",
    "    boundary_edges = sum(1 for _ in boundary_edge_iter)\n",
    "    return boundary_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The normalized-cut cost of the 50/50 split is 0.3948717948717949\n"
     ]
    }
   ],
   "source": [
    "high = sum([largest.degree[v] for v in highest])\n",
    "low = sum([largest.degree[w] for w in lowest])\n",
    "total_edges = nedges(largest, highest, lowest)\n",
    "Cost = (total_edges/high + total_edges/low) / 2\n",
    "print(\"The normalized-cut cost of the 50/50 split is \"+str(Cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Tdegree(g, c):\n",
    "    degree = sum([g.degree[v] for v in c])\n",
    "    return degree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_cost(g, c1, c2):\n",
    "    N = nedges(g, c1, c2)\n",
    "    sum1 = Tdegree(g, c1)\n",
    "    sum2 = Tdegree(g, c2)\n",
    "    return (N/sum1 + N/sum2) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each node in high, calculate normalized cut cost after moving to low\n",
    "# for each node in low, calculate normalized cut cost after moving to high\n",
    "# choose node move resulting in lowest normalized cut cost.\n",
    "# Repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowest_cost_node(g, c1, c2):\n",
    "\n",
    "    min_cost = float('inf')\n",
    "\n",
    "    for n in c1:\n",
    "        trial_set1 = c1.copy()\n",
    "        trial_set2 = c2.copy()\n",
    "        trial_set1.remove(n)\n",
    "        trial_set2.append(n)\n",
    "\n",
    "        c = cut_cost(g,trial_set1,trial_set2)\n",
    "        if c < min_cost:\n",
    "            min_cost = c\n",
    "            min_node = n\n",
    "        elif c == min_cost:\n",
    "            if n < min_node:\n",
    "                min_node = n\n",
    "\n",
    "        #N = nedges(largest, trial_set1, trial_set2)\n",
    "        #sum1 = Tdegree(largest, trial_set1)\n",
    "        #sum2 = Tdegree(largest, trial_set2)\n",
    "        #print(\"N: \" + str(N) + \" sum1: \" + str(sum1) + \" sum2: \" + str(sum2) + \"cut cost:\" + str(c))\n",
    "\n",
    "    print( \"min node: \" + str(min_node) + \" min cost: \" + str(min_cost)  )\n",
    "    return min_node,min_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cur_cost: 0.3948717948717949\n",
      "min node: 828 min cost: 0.3575324472940181\n",
      "min node: 729 min cost: 0.3561891545238546\n",
      "moving node: 729\n",
      "cur_cost: 0.3561891545238546\n",
      "min node: 828 min cost: 0.314994793474488\n",
      "min node: 804 min cost: 0.31117397454031115\n",
      "moving node: 804\n",
      "cur_cost: 0.31117397454031115\n",
      "min node: 828 min cost: 0.26663264655227403\n",
      "min node: 803 min cost: 0.3059678256357032\n",
      "moving node: 828\n",
      "cur_cost: 0.26663264655227403\n",
      "min node: 830 min cost: 0.2257691215965414\n",
      "min node: 803 min cost: 0.2607738548810431\n",
      "moving node: 830\n",
      "cur_cost: 0.2257691215965414\n",
      "min node: 840 min cost: 0.17876489707475623\n",
      "min node: 803 min cost: 0.21954182575494618\n",
      "moving node: 840\n",
      "cur_cost: 0.17876489707475623\n",
      "min node: 880 min cost: 0.14714361493576883\n",
      "min node: 753 min cost: 0.17854401087934021\n",
      "moving node: 880\n",
      "cur_cost: 0.14714361493576883\n",
      "min node: 890 min cost: 0.1295001295001295\n",
      "min node: 753 min cost: 0.14732142857142858\n",
      "moving node: 890\n",
      "cur_cost: 0.1295001295001295\n",
      "min node: 869 min cost: 0.11129580111295802\n",
      "min node: 798 min cost: 0.1341966966966967\n",
      "moving node: 869\n",
      "cur_cost: 0.11129580111295802\n",
      "min node: 856 min cost: 0.09817045961624274\n",
      "min node: 798 min cost: 0.11613398598713887\n",
      "moving node: 856\n",
      "cur_cost: 0.09817045961624274\n",
      "min node: 893 min cost: 0.10632551528073916\n",
      "min node: 798 min cost: 0.1036614096843039\n",
      "The first cluster is: [825, 861, 863, 864, 876, 878, 882, 884, 886, 888, 889, 893, 729, 804]\n",
      "The second cluster is: [697, 703, 708, 713, 719, 745, 747, 753, 769, 772, 774, 798, 800, 803, 805, 810, 811, 819, 823, 828, 830, 840, 880, 890, 869, 856]\n",
      "The minimum normalized cut cost is: 0.09817045961624274\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    # FIRST calculate current cut cost\n",
    "    cur_cost = cut_cost(largest, highest, lowest)\n",
    "    print(\"cur_cost: \" + str(cur_cost))\n",
    "    # find smallest cost move from high to low\n",
    "    h2l_node,h2l_cost = lowest_cost_node(largest, highest, lowest)\n",
    "    # find smallest cost move from low to high\n",
    "    l2h_node,l2h_cost = lowest_cost_node(largest, lowest, highest)\n",
    "    # if one of those moves is less than current cut, then move node and repeat\n",
    "    if h2l_cost < l2h_cost and h2l_cost < cur_cost:\n",
    "        #move node from highest to lowest\n",
    "        highest.remove(h2l_node)\n",
    "        lowest.append(h2l_node)\n",
    "        print(\"moving node: \" + str(h2l_node))\n",
    "    elif l2h_cost < h2l_cost and l2h_cost < cur_cost:\n",
    "        # move node from lowest to highest\n",
    "        lowest.remove(l2h_node)\n",
    "        highest.append(l2h_node)\n",
    "        print(\"moving node: \" + str(l2h_node))\n",
    "    elif l2h_cost == h2l_cost:\n",
    "        # move node with lower index\n",
    "        if l2h_node < h2l_node:\n",
    "            lowest.remove(l2h_node)\n",
    "            highest.append(l2h_node)\n",
    "            print(\"moving node: \" + str(l2h_node))\n",
    "        else:\n",
    "            highest.remove(h2l_node)\n",
    "            lowest.append(h2l_node)\n",
    "            print(\"moving node: \" + str(h2l_node))\n",
    "    else:\n",
    "        # done\n",
    "        break\n",
    "        \n",
    "print(\"The first cluster is: \" + str(highest))\n",
    "print(\"The second cluster is: \" + str(lowest))\n",
    "print(\"The minimum normalized cut cost is: \" + str(cut_cost(largest, highest, lowest)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_community_node(g, c1, c2):\n",
    "\n",
    "    max_community = -float('inf')\n",
    "\n",
    "    for n in c1:\n",
    "        trial_set1 = c1.copy()\n",
    "        trial_set2 = c2.copy()\n",
    "        trial_set1.remove(n)\n",
    "        trial_set2.append(n)\n",
    "\n",
    "        c = community(g,trial_set1,trial_set2)\n",
    "        if c > max_community:\n",
    "            max_community = c\n",
    "            max_node = n\n",
    "        elif c == max_community:\n",
    "            if n < max_node:\n",
    "                max_node = n\n",
    "\n",
    "\n",
    "    print( \"max node: \" + str(max_node) + \" mac community: \" + str(max_community)  )\n",
    "    return max_node,max_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "def community(g, c1, c2):\n",
    "\n",
    "    total_edges = 0\n",
    "    for e in g.edges():\n",
    "        total_edges += 1\n",
    "\n",
    "    total_endpoints = total_edges * 2\n",
    "\n",
    "    s1 = g.subgraph(c1)\n",
    "    e1 = Tdegree(s1, c1) / total_endpoints\n",
    "    a1 = Tdegree(g, c1) / total_endpoints\n",
    "    \n",
    "    C1 = e1 - (a1 ** 2)\n",
    "    \n",
    "    s2 = g.subgraph(c2)\n",
    "    e2 = Tdegree(s2, c2) / total_endpoints\n",
    "    a2 = Tdegree(g, c2) / total_endpoints\n",
    "    \n",
    "    C2 = e2 - (a2 ** 2)\n",
    "\n",
    "    return (C1 + C2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "highest = sorted(largest.nodes())[21:]\n",
    "\n",
    "\n",
    "lowest = sorted(largest.nodes())[:21]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cur_comm: 0.1016528925619834\n",
      "max node: 828 mac community: 0.13222107438016542\n",
      "max node: 729 mac community: 0.1413119834710744\n",
      "moving node: 729\n",
      "cur_comm: 0.1413119834710744\n",
      "max node: 828 mac community: 0.17619834710743798\n",
      "max node: 804 mac community: 0.18756198347107442\n",
      "moving node: 804\n",
      "cur_comm: 0.18756198347107442\n",
      "max node: 828 mac community: 0.22676652892561983\n",
      "max node: 803 mac community: 0.1931301652892563\n",
      "moving node: 828\n",
      "cur_comm: 0.22676652892561983\n",
      "max node: 830 mac community: 0.2594938016528925\n",
      "max node: 803 mac community: 0.2335123966942149\n",
      "moving node: 830\n",
      "cur_comm: 0.2594938016528925\n",
      "max node: 840 mac community: 0.2940495867768594\n",
      "max node: 803 mac community: 0.26710743801652886\n",
      "moving node: 840\n",
      "cur_comm: 0.2940495867768594\n",
      "max node: 880 mac community: 0.31610537190082644\n",
      "max node: 753 mac community: 0.30279958677685953\n",
      "moving node: 880\n",
      "cur_comm: 0.31610537190082644\n",
      "max node: 890 mac community: 0.32511363636363627\n",
      "max node: 753 mac community: 0.3264462809917356\n",
      "moving node: 753\n",
      "cur_comm: 0.3264462809917356\n",
      "max node: 869 mac community: 0.32772727272727264\n",
      "max node: 811 mac community: 0.3300723140495868\n",
      "moving node: 811\n",
      "cur_comm: 0.3300723140495868\n",
      "max node: 811 mac community: 0.3264462809917356\n",
      "max node: 769 mac community: 0.3326342975206613\n",
      "moving node: 769\n",
      "cur_comm: 0.3326342975206613\n",
      "max node: 769 mac community: 0.3300723140495868\n",
      "max node: 798 mac community: 0.33801652892561973\n",
      "moving node: 798\n",
      "cur_comm: 0.33801652892561973\n",
      "max node: 798 mac community: 0.3326342975206613\n",
      "max node: 803 mac community: 0.3267665289256198\n",
      "Cluster one: [825, 856, 861, 863, 864, 869, 876, 878, 882, 884, 886, 888, 889, 890, 893, 729, 804, 753, 811, 769, 798]\n",
      "Cluster two: [697, 703, 708, 713, 719, 745, 747, 772, 774, 800, 803, 805, 810, 819, 823, 828, 830, 840, 880]\n",
      "Max modularity values for the 50/50 spl is: 0.33801652892561973\n"
     ]
    }
   ],
   "source": [
    "\n",
    "while True:\n",
    "    # FIRST calculate current community\n",
    "    cur_comm = community(largest, highest, lowest)\n",
    "    print(\"cur_comm: \" + str(cur_comm))\n",
    "    # find smallest cost move from high to low\n",
    "    h2l_node,h2l_cost = best_community_node(largest, highest, lowest)\n",
    "    # find smallest cost move from low to high\n",
    "    l2h_node,l2h_cost = best_community_node(largest, lowest, highest)\n",
    "    # if one of those moves is less than current cut, then move node and repeat\n",
    "    if h2l_cost > l2h_cost and h2l_cost > cur_comm:\n",
    "        #move node from highest to lowest\n",
    "        highest.remove(h2l_node)\n",
    "        lowest.append(h2l_node)\n",
    "        print(\"moving node: \" + str(h2l_node))\n",
    "    elif l2h_cost > h2l_cost and l2h_cost > cur_comm:\n",
    "        # move node from lowest to highest\n",
    "        lowest.remove(l2h_node)\n",
    "        highest.append(l2h_node)\n",
    "        print(\"moving node: \" + str(l2h_node))\n",
    "    elif l2h_cost == h2l_cost:\n",
    "        # move node with lower index\n",
    "        if l2h_node < h2l_node:\n",
    "            lowest.remove(l2h_node)\n",
    "            highest.append(l2h_node)\n",
    "            print(\"moving node: \" + str(l2h_node))\n",
    "        else:\n",
    "            highest.remove(h2l_node)\n",
    "            lowest.append(h2l_node)\n",
    "            print(\"moving node: \" + str(h2l_node))\n",
    "    else:\n",
    "        # done\n",
    "        break\n",
    "        \n",
    "print(\"Cluster one: \" + str(highest))\n",
    "print(\"Cluster two: \" + str(lowest))\n",
    "print(\"Max modularity values for the 50/50 spl is: \" + str(community(largest, highest, lowest)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
