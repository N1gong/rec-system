{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nawen Gong\n",
    "\n",
    "PID: A53275627"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import urllib\n",
    "import scipy.optimize\n",
    "from sklearn import svm\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseData(fname):\n",
    "  for l in urllib.request.urlopen(fname):\n",
    "    yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(parseData(\"http://jmcauley.ucsd.edu/cse258/data/beer/beer_50000.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [d['review/taste'] for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## What is the distribution of ratings in the dataset (for ‘review/taste’)? That is, how many 1-star, 2-star, 3-star (etc.) reviews are there? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_stars, counts_starts = np.unique(np.array(y), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    1.      1.5     2.      2.5     3.      3.5     4.      4.5     5. ]\n",
      " [  211.    343.   1099.   1624.   4137.   8797.  16575.  12883.   4331. ]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "print(np.asarray((unique_stars, counts_starts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = []\n",
    "\n",
    "for d in data:\n",
    "    if 'beer/style' in d and 'beer/ABV' in d and 'review/taste' in d:\n",
    "        data2.append(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature(datum):\n",
    "  feat = [1]\n",
    "  if 'Hefeweizen' == datum['beer/style']:\n",
    "    feat.append(1)\n",
    "  else:\n",
    "    feat.append(0)\n",
    "  feat.append(datum['beer/ABV'])\n",
    "  return feat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = [feature(d) for d in data2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [d['review/taste'] for d in data2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta,residuals,rank,s = np.linalg.lstsq(X1,y,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta: [ 3.11795084 -0.05637406  0.10877902]\n"
     ]
    }
   ],
   "source": [
    "print(\"theta: \" + str(theta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theta0 is the first value in the list 'theta' and it represents the intercept of the linear function. \n",
    "Theta1 is the second value in the list 'theta' and it represents the coefficient between the first feature 'beer is a Hefeweizen' and the predicted value 'review/taste'.\n",
    "Theta2 is the third value in the list 'theta' and it represents the coefficient between the second feature 'beer/ABV' and the predicted value 'review/taste'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "residuals: [22482.91275121]\n"
     ]
    }
   ],
   "source": [
    "print(\"residuals: \" + str(residuals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank: 3\n"
     ]
    }
   ],
   "source": [
    "print(\"rank: \" + str(rank))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s: [1747.0976296    66.41497289   24.54093593]\n"
     ]
    }
   ],
   "source": [
    "print(\"s: \" + str(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Split the data into two equal fractions – the first half for training, the second half for testing (based on\n",
    "the order they appear in the file). Train the same model as above on the training set only. What is the\n",
    "model’s MSE on the training and on the test set (1 mark)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.5*len(data2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train = data2[:n]\n",
    "d_target = data2[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [feature(d) for d in d_train]\n",
    "y_train = [d['review/taste'] for d in d_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta,residuals,rank,s = np.linalg.lstsq(X_train,y_train,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta: [ 2.99691466 -0.03573098  0.11672256] residuals: [12099.20140034] rank: 3 s: [1299.09816954   44.96451837   17.13837497]\n"
     ]
    }
   ],
   "source": [
    "print(\"theta: \" + str(theta), \"residuals: \" + str(residuals), \"rank: \" + str(rank), \"s: \" + str(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for training set is:0.23422507924140004\n"
     ]
    }
   ],
   "source": [
    "MSE_train = np.mean((residuals/len(d_train)) ** 2)\n",
    "print(\"MSE for training set is:\" + str(MSE_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_target = [feature(d) for d in d_target]\n",
    "y_target = [d['review/taste'] for d in d_target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = reg.predict(X_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_target = mean_squared_error(y_target, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for atrget set is:0.4237065211985229\n"
     ]
    }
   ],
   "source": [
    "print(\"MSE for atrget set is:\" + str(MSE_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.Using the first half for training and the second half for testing may lead to unexpected results (e.g. the\n",
    "training error could be higher than the test error). Repeat the above experiment by using a random 50%\n",
    "split of the data (i.e., half for training, half for testing, after first shuffling the data). Report the MSE on\n",
    "the train and test set, and suggest one possible reason why the result may be different from the previous\n",
    "experiment (1 mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_r = random.sample(data2, int(len(data2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train_r = int(0.5*len(data_r))\n",
    "n_target_r =  int(0.5*len(data_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train_r = data_r[:n_train_r]\n",
    "d_target_r = data_r[n_target_r:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_r = [feature(d) for d in d_train_r]\n",
    "y_train_r = [d['review/taste'] for d in d_train_r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_target_r = [feature(d) for d in d_target_r]\n",
    "y_target_r = [d['review/taste'] for d in d_target_r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta,residuals,rank,s = np.linalg.lstsq(X_train_r,y_train_r,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_train_rand = np.mean((residuals/len(d_train_r)) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for training set is:0.20151436535640052\n"
     ]
    }
   ],
   "source": [
    "print(\"MSE for training set is:\" + str(MSE_train_rand))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression().fit(X_train_r, y_train_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_r = reg.predict(X_target_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_target_rand = mean_squared_error(y_target_r, y_pred_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for target set is:0.45042666099361456\n"
     ]
    }
   ],
   "source": [
    "print(\"MSE for target set is:\" + str(MSE_target_rand))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One possible factor that differentiates the MSE between shuffled and non-shuffled data is that, if we don't shuffle data to split it 50-50, the first half using as the training set from the original data might contain patterns, making the predictor biased and weakening its ability to predict appropriately. Shuffling the training data removes any ordering influence from how the data was gathered or prepared.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.Modify your experiment from Question 4 to use the features\n",
    "review/taste ' θ0 + θ1 × [ABV if beer is a Hefeweizen] + θ2 × [ABV if beer is not a Hefeweizen]\n",
    "e.g. the first beer in the dataset would have feature [1, 5.0, 0] since the beer is a Hefeweizen. Report the\n",
    "training and testing MSE of this method (1 mark)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature2(datum):\n",
    "  feat2 = [1]\n",
    "  if 'Hefeweizen' == datum['beer/style']:\n",
    "    feat2.append(datum['beer/ABV'])\n",
    "    feat2.append(0)\n",
    "  else:\n",
    "    feat2.append(0)\n",
    "    feat2.append(datum['beer/ABV'])\n",
    "\n",
    "  return feat2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_r = random.sample(data2, int(len(data2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train_r = int(0.5*len(data_r))\n",
    "n_target_r =  int(0.5*len(data_r))\n",
    "\n",
    "d_train_r = data_r[:n_train_r]\n",
    "d_target_r = data_r[n_target_r:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_r = [feature2(d) for d in d_train_r]\n",
    "y_train_r = [d['review/taste'] for d in d_train_r]\n",
    "\n",
    "X_target_r = [feature2(d) for d in d_target_r]\n",
    "y_target_r = [d['review/taste'] for d in d_target_r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for training set is:0.20366353344910615\n"
     ]
    }
   ],
   "source": [
    "theta,residuals,rank,s = np.linalg.lstsq(X_train_r,y_train_r,-1)\n",
    "MSE_train_rand = np.mean((residuals/len(d_train_r)) ** 2)\n",
    "\n",
    "print(\"MSE for training set is:\" + str(MSE_train_rand))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression().fit(X_train_r, y_train_r)\n",
    "y_pred_r = reg.predict(X_target_r)\n",
    "MSE_target_rand = mean_squared_error(y_target_r, y_pred_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for target set is:0.44804653288701185\n"
     ]
    }
   ],
   "source": [
    "print(\"MSE for target set is:\" + str(MSE_target_rand))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.The model from Question 5 uses the same two features as the model from Questions 2-4 and has the\n",
    "same dimensionality. Comment on why the two models might perform differently (1 mark).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictor used in question 2-4 makes predictions by learning the correlations of 'review/taste' and 'a beer is Hefeweizen' and the correlations of 'review/taste' and each beer's ABV.\n",
    "\n",
    "The predictor used in question 5 makes predictions by studying the patterns between 'review/taste' and Hefeweizen's ABV and patterns between 'review/taste' and non-Hefeweizen's ABV.\n",
    "\n",
    "The predictors predicts by learning different patterns that's why the two model performs differently. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. First, let’s train a predictor that estimates whether a beer is a ‘Hefeweizen’ using five features describing\n",
    "its rating:\n",
    "[‘review/taste’, ‘review/appearance’, ‘review/aroma’, ‘review/palate’, ‘review/overall’].\n",
    "Train your predictor using an SVM classifier (see the code provided in class). Use a random split of the\n",
    "data as we did in Question 4. Use a regularization constant of C = 1000 as in the code stub. What is\n",
    "the accuracy (percentage of correct classifications) of the predictor on the train and test data? (1 mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = []\n",
    "for d in data:\n",
    "    if 'review/taste' in d and 'review/appearance' in d and 'review/aroma' in d and 'review/palate' in d and 'review/overall' in d:\n",
    "        data3.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data4 = random.sample(data3, int(len(data3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [[b['review/taste'], b['review/appearance'], b['review/aroma'], b['review/palate'], b['review/overall']] for b in data4]\n",
    "y = ['Hefeweizen' in b['beer/style'] for b in data4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(len(data4) * 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[:25000]\n",
    "y_train = y[:25000]\n",
    "\n",
    "X_test = X[25000:]\n",
    "y_test = y[25000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(C=1000, kernel='linear')\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = clf.predict(X_train)\n",
    "test_predictions = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy of the train data is:0.98672\n"
     ]
    }
   ],
   "source": [
    "pct_train = np.mean(train_predictions == y_train)\n",
    "print(\"the accuracy of the train data is:\" + str(pct_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy of the test data is:0.98856\n"
     ]
    }
   ],
   "source": [
    "pct_test = np.mean(test_predictions == y_test)\n",
    "print(\"the accuracy of the test data is:\" + str(pct_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.Considering same prediction problem as above, can you come up with a more accurate predictor (e.g. using\n",
    "features from the text, or otherwise)? Write down the feature vector you design, and report its train/test\n",
    "accuracy (1 mark)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will add beer/name as a feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = ['review/taste', 'review/appearance', 'review/aroma', 'review/palate', 'review/overall', 'beer/name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "data5 = []\n",
    "\n",
    "for d in data:\n",
    "    if 'review/taste' in d and 'review/appearance' in d and 'review/aroma' in d and 'review/palate' in d and 'review/overall' in d and 'beer/name' in d:\n",
    "        data5.append(d)\n",
    "data5 = random.sample(data5, int(len(data5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = ['HEFE', 'HEIFER', 'WEIZEN', 'HEFEWEIZEN', 'WHEAT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature(datum):\n",
    "    if any(p in datum['beer/name'].upper() for p in pattern):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [[b['review/taste'], b['review/appearance'], b['review/aroma'], b['review/palate'], b['review/overall'], feature(b)] for b in data5]\n",
    "y = ['Hefeweizen' in b['beer/style'] for b in data5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[:25000]\n",
    "y_train = y[:25000]\n",
    "\n",
    "X_test = X[25000:]\n",
    "y_test = y[25000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(C=1000, kernel='linear')\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = clf.predict(X_train)\n",
    "test_predictions = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy of the train data is:0.99096\n"
     ]
    }
   ],
   "source": [
    "pct_train = np.mean(train_predictions == y_train)\n",
    "print(\"the accuracy of the train data is:\" + str(pct_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy of the test data is:0.99036\n"
     ]
    }
   ],
   "source": [
    "pct_test = np.mean(test_predictions == y_test)\n",
    "print(\"the accuracy of the test data is:\" + str(pct_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
